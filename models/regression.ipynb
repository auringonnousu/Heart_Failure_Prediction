{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binominal Logistic Regression\n",
    "\n",
    "Regression estimates the relationship between a target outcome label and one or more feature variables to predict a continuous numeric value.\n",
    "\n",
    "Logistic regression is a classification model that uses input variables (features) to predict a categorical outcome variable (label) that can take on one of a limited set of class values. A binomial logistic regression is limited to two binary output categories, while a multinomial logistic regression allows for more than two classes. Examples of logistic regression include classifying a binary condition as “healthy”/“not healthy”, or an image as “bicycle”/“train”/“car”/“truck”.\n",
    "\n",
    "Logistic regression applies the logistic sigmoid function to weighted input values to generate a prediction of the data class.\n",
    "\n",
    "A logistic regression model estimates the probability of a dependent variable as a function of independent variables. The dependent variable is the output (label) that we are trying to predict, while the independent variables or features are the factors that we feel could influence the output.\n",
    "\n",
    "A generalized linear regression doesn’t need the data input to have a normal distribution. The test data can have any distribution. Logistic regression is a special case of the generalized linear regression where the response variable follows the logit function. The input of the logit function is a probability p, between 0 and 1. The odds ratio for probability p is defined as p/(1-p), and the logit function is defined as the logarithm of the Odds ratio or log-odds.\n",
    "\n",
    "Logit(p) = Log(odds) = Log (p/(1-p))\n",
    "\n",
    "The quality of a logistic regression model is determined by measures of fit and predictive power. R-squared is a measure of how well the independent variable in the logistic function can be predicted from the dependent variables, and ranges from 0 to 1. Many different ways exist to calculate R-square including the Cox-Snell R2 and the McFadden R2. Goodness of fit, on the other hand, can be measured using tests such as the Pearson chi-square, Hosmer-Lemeshow, and Stukel tests. The right type of test to use will depend on factors such as the distribution of p-values, interactions and quadratic effects, and grouping of data.\n",
    "\n",
    "Logistic regression is similar to a non-linear perceptron or a neural network without hidden layers. Logistic regression is most valuable for areas where data are scarce, like the medical and social sciences where it’s used to analyze and interpret results from experiments. Because regression is simple and fast, it’s also used for very large data sets. Logistic regression, however, cannot be applied to predict continuous outcomes or used with data sets that are not independent. There’s also a possibility of overfitting the model to the data when using logistic regression.\n",
    "\n",
    "https://www.nvidia.com/en-us/glossary/linear-regression-logistic-regression/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_after_EDA.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amoount of features after using OneHotEncoder: 21\n"
     ]
    }
   ],
   "source": [
    "categorical_feat = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "categorical_data = df[categorical_feat]\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(categorical_data)\n",
    "encoded_data = encoder.transform(categorical_data)\n",
    "\n",
    "# Concat data to original\n",
    "edcoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out(categorical_feat))\n",
    "df_encoded = pd.concat([df.drop(categorical_feat, axis=1), edcoded_df], axis=1)\n",
    "print(f'Amoount of features after using OneHotEncoder: {len(df_encoded.columns)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split target (y) from features (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop('HeartDisease', axis=1)\n",
    "y = df_encoded['HeartDisease']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape Counter({1: 344, 0: 298})\n",
      "Testing set shape Counter({1: 164, 0: 112})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "print(f'Training set shape {Counter(y_train)}')\n",
    "print(f'Testing set shape {Counter(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    target_names = ['Class 0', 'Class 1']\n",
    "    return print(classification_report(y_test, y_pred, target_names=target_names, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0    0.81301   0.89286   0.85106       112\n",
      "     Class 1    0.92157   0.85976   0.88959       164\n",
      "\n",
      "    accuracy                        0.87319       276\n",
      "   macro avg    0.86729   0.87631   0.87033       276\n",
      "weighted avg    0.87752   0.87319   0.87396       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier_lg = LogisticRegression(random_state=42)\n",
    "model(classifier_lg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
